%!TEX root = thesis.tex

\chapter{Experiments}
\label{ch:experiments}


\section{The dataset}
A dataset was constructed to perform the experiments. The dataset consists of movies with people performing all 28 hand poses. Per movie 28 frames where manually picked out and labeled where the person was performing the pose correctly. In total there are 74 movies containing 20 different people performing the complete sequence of 28 hand symbols. In the beginning people where recorded performing the complete sequence 5 times, but this was taking too much time. After we switched to 3 movies per person. The movies where recorded with Sonic Gesture, with a resolution of 532x400 and a frame rate of 10. The test subjects where recorded while looking at a computer screen and asked to mimic the examples as in \autoref{fig:hands}. The movies with 12 test subjects where recorded with a simple (almost empty and smooth) background, 3 where recorded with a complex background and 6 where recorded with the same complex background but also with a poster with skinlike colors.



\begin{table}
\centering
\begin{tabular}{llll}
\hline\hline
	Test Subject & Movies & Background & Notes \\
\hline
	Anne     & 5 & Simple & None \\
	Arjan    & 5 & Simple & None \\
	Gijs     & 5 & Simple & None \\
	Ivo      & 5 & Simple & None \\
	Jasper 1 & 5 & Simple & None \\
	Peter    & 5 & Simple & None \\
	Hanne    & 5 & Simple & None \\
	Jasper 2 & 3 & Simple & None \\
	Ork      & 3 & Simple & None \\
	Roberto  & 3 & Simple & None \\
	Xiaong   & 3 & Simple & None \\
	\hline			
	Gosia    & 3 & Complex & None \\
	Hamdi    & 3 & Complex & None \\
	Michael  & 3 & Complex & None \\
	Sil      & 3 & Complex + skin-like colors & None \\
	Victoria & 3 & Complex + skin-like colors & None \\
	Chu      & 3 & Complex + skin-like colors & problem with brick wall \\
	\hline	
	Bas      & 3 & Complex + skin-like colors & None \\
	Koen     & 3 & Complex + skin-like colors & None \\
	Stratos  & 3 & Complex + skin-like colors & problems with white wall \\
\hline
\end{tabular}
\caption{Dataset details}
\end{table}


\begin{figure}[htbp]
\center{}
\includegraphics[width=0.8\linewidth]{figures/simple.png}
\caption{Still of movie ivo5 with simple background}
\label{fig:simplebackground}
\end{figure}

\begin{figure}[htbp]
\center{}
\includegraphics[width=0.8\linewidth]{figures/complex.png}
\caption{Still of movie sil1 with simple background}
\label{fig:complexbackground}
\end{figure}


The dataset is manually labeled. For every sequence of frames where a hand pose is performed a frame number is labeled where the pose resembles the example the most. \autoref{fig:gijs5} is an example of the labeled frames. The train images used to train the classifier where extracted with Sonic Gesture

Usually the 12 Curwen solfege hand symbols are performed in front of the torso as shown in \autoref{fig:hands}. To increase the number of hand poses to be recognized, all 12 Curwen are also performed mirrored next to the body of the recorded subject, see \autoref{fig:hands}. Additionally four extra hand symbols have been added that are not part of the Curwen sequence, see \autoref{fig:hands}. These last four symbols are performed next to the head.

\section{Evaluation}


\section{Results}

\subsection{part I}
For the number of neighbors for K-NN a small number of tests where run, and a value between 3 and 10 for N yielded similar performance. Since a lower number of $k$ can give better performance $k=3$ was used for all experiments.

When PCA was performed on the dataset the smallest eigenvectors where removed so 95\% of the original variance was kept.

For SVM the radial basis function (RBF) kernel is used, since the libsvm documentation states that is a good kernel to use that usually gives good performance. The $c$ and $\gamma$ values for SVM where found by an extensive grid search on the 'per person' tests with only the simple movies performed on a small cluster in the ranges $2.^(-3:2:15)$ for $c$ and $2.^(-15:2:3)$ for $\gamma$. The most optimal values are $\gamma$ = 0.03125. With this $\gamma$ changing the value for $c$ didn't have much effect on the performance, so a value of 64 was taken.

The Curwen hand symbols that are closely related in a musical scale way are quite similar, for example 'Re' and 'Ri' (\autoref{fig:reri}). It is expected that a lot of misclassifications will be caused by this similarity. To investigate the impact of this issue, 2 different scores are calculated, one for the major scale and one for the full scale. The full scale threats every class as a single class, for the major scale the notes in the major scale and their corresponding similar notes are joined into one class. For example Do an

\begin{figure}[htbp]
  \centering
\subfloat[Re]{\includegraphics[width=0.2\linewidth,height=0.15\linewidth]{figures/examples/2.jpg}}
\hspace{0.03\linewidth}
\subfloat[Ri]{\includegraphics[width=0.2\linewidth,height=0.15\linewidth]{figures/examples/3.jpg}}
  \caption{The hand symbols for Re and Ri}
  \label{fig:reri}
\end{figure}




Doing PCA and removing eigenvectors untill 0.95 variance on the simple data set will reduce to  594 dimensions (from 3780);
complex + simple: 688
complex:  283
full: 749


\begin{table}
\centering
\begin{tabular}{lrr}
\hline\hline
Classifier 				&  	Full scale	& Major scale	\\
\hline
KNN3 		&  	84.27\%		& 90.21\%		\\
PCA, KNN3 	& 	83.67\%		& 89.70\%		\\
PCA, SVM RBF ($c=1$ $\gamma=\frac{1}{|features|}$)	& 	76.78\%		& 84.38\%		\\
SVM RBF ($c=2^6$ $\gamma=2^{-5}$) & 86.02\% & 90.88\% \\
PCA, SVM RBF ($c=2^6$ $\gamma=2^{-5}$) &  86.85\% & 91.85\% \\
SVM $\chi^2$ & 87.92\% 		& 91.58\% \\
\hline
\end{tabular}
\caption{k-fold per film using simple dataset only}
\end{table}


\begin{table}
\centering
\begin{tabular}{llrr}
\hline\hline
Dataset & Classifier 				&  	Full scale	& Major scale	\\
\hline
simple set	& KNN3	& 72.93\%, & 82.63\%	\\
simple set	& PCA, SVM RBF ($c=2^6$ $\gamma=2^{-5}$) & 79.71\%, & 86.70\%	\\
full set	& KNN3 & 66.98\%, & 76.32\%	\\
full set	& PCA, KNN3 & 65.31\%, & 76.00\%	\\
full set	& PCA, SVM RBF ($c=1$ $\gamma=\frac{1}{|features|}$) & 64.05\%, & 74.42\%	\\
full set	& PCA, SVM RBF ($c=2^6$ $\gamma=2^{-5}$)& 73.38\%, & 81.44\%	\\
full set    & SVM $\chi^2$ &  71.83\% &80.07\% \\
\hline
\end{tabular}
\caption{k-fold per person}
\end{table}


\begin{table}
\centering
\begin{tabular}{lcc}
\hline\hline
Classifier 				&  	Full scale	&	Major scale	\\
\hline
KNN3					&	58.57\% 	&	72.78\%	\\
PCA, KNN3 				&	57.62\% 	&	72.17\%	\\
PCA, SVM RBF ($c=1$ $\gamma=\frac{1}{|features|}$)	& 55.48\%	&	68.25\%	\\
PCA, SVM RBF ($c=2^6$ $\gamma=2^{-5}$)				& 62.14\%	&	73.39\%	\\
SVM $\chi^2$ 			&	63.81\%		&	74.71\%	\\
\hline
\end{tabular}
\caption{simple as trainset, complex as test}
\end{table}



\begin{figure}[htbp]
\begin{center}
\label{fig:confusion}
\includegraphics[width=\linewidth]{confmat/confusion.jpg}
\end{center}
\caption{confusion matrix, SVM $\chi^2$, n-fold, per film simple set}
\end{figure}

%>> sum((ones(28,28)-eye(28)).* C)
%6     6     7     6    17     5    14     1     0     3     5     3     3     %1     6    13    10     5     6     5     2     8    10     4     0     0     %1    12



\subsection{Part II}

\begin{figure}[htbp]
\center{}
\subfloat[Without stabilizer]{
	\includegraphics[width=0.3\linewidth]{figures/performance/anne1_unstable.jpg}}
\hspace{0.02\linewidth}
\subfloat[With stabilizer]{
	\includegraphics[width=0.3\linewidth]{figures/performance/anne1_stable.jpg}}
\hspace{0.02\linewidth}
\subfloat[Arbitrary movie with stabilizer]{
	\includegraphics[width=0.3\linewidth]{figures/performance/heilige.jpg}}
\caption{Plots of labels per frame}
\label{fig:performances}
\end{figure}

For this set of experiments the Damerau-Levenshtein distance of a sequence of generated labels to the ground truth is calculated. This value is then divided by the number of labels, 28. A low value is equal to good performance, a high value to bad. The ground truth is a list of incremented integers from 1 to 28. Since some movies are 'polluted' with incorrect hand poses and other people walking through the screen this ground truth isn't really correct. But it is very difficult to impossible to construct a good ground truth in this case, and given the fact that the goal of the recorded movies was to have people perform the 28 hand poses sequentially this is a good alternative.

simple: 0.27 average\\
complex: 0.35 average\\

ivo 0.08\\
hanne 0.14\\
gijs 0.18\\
ork 0.18\\
chu 0.19\\
jasberb 0.23\\
stratos 0.24\\
victoria 0.24\\
arjan 0.26\\
peter 0.26\\
anne 0.28\\
michael 0.32\\
gosia 0.37\\
koen 0.38\\
jasper  0.4\\
bas 0.44\\
roberto 0.47\\
xiaong 0.49\\
hamdi 0.49\\
sil 0.52\\




anne1 25.0
anne2 24.0
anne3 25.0
anne4 25.0
anne5 24.0
arjan1 24.0
arjan2 22.0
arjan3 25.0
arjan4 23.0
arjan5 22.0
bas1 25.0
bas2 26.0
bas3 25.0
chu1 26.0
chu2 25.0
chu3 24.0
gijs1 25.0
gijs2 23.0
gijs3 23.0
gijs4 27.0
gijs5 24.0
gosia1 24.0
gosia2 25.0
gosia3 25.0
hamdi1 24.0
hamdy2 25.0
hamdy3 24.0
hanne1 26.0
hanne2 25.0
hanne3 25.0
hanne4 25.0
hanne5 26.0
ivo1 26.0
ivo2 24.0
ivo3 24.0
ivo4 24.0
ivo5 23.0
jasper1 25.0
jasper2 23.0
jasper3 24.0
jasper4 23.0
jasper5 25.0
jasperb1 24.0
jasperb2 26.0
jasperb3 26.0
koen1 24.0
koen2 25.0
koen3 25.0
michael1 26.0
michael2 26.0
michael3 24.0
ork1 23.0
ork2 24.0
ork3 25.0
peter1 25.0
peter2 24.0
peter3 24.0
peter4 26.0
peter5 25.0
roberto1 23.0
roberto2 24.0
roberto3 23.0
sil1 23.0
sil2 24.0
sil3 23.0
stratos1 23.0
stratos2 25.0
stratos3 24.0
victoria1 25.0
victoria2 25.0
victoria3 24.0
xiaong1 24.0
xiaong2 26.0
xiaong3 24.0


\begin{tabular}{rrrrrrr}
\hline
name	& 1 & 2 & 3 & 4 & 5 & normalized average \\
\hline
Anne	&	12.0	&	9.0		&	7.0	&	8.0	&	4.0	&	0.28\\
Arjan	&	13.0	&	7.0		&	7.0	&	2.0	&	8.0	&	0.26\\
Gijs	&	4.0		&	5.0		&	6.0	&	6.0	&	4.0	&	0.18\\
Ivo		&	2.0		&	3.0		&	2.0	&	3.0	&	1.0	&	0.08\\
Jasper 1	&	19.0	&	13.0	&	6.0	&	6.0	&	12.0 &	0.4\\
Peter	&	7.0		&	8.0		&	7.0	&	9.0	&	5.0	&	0.26\\
Hanne	&	9.0		&	0.0		&	1.0	&	7.0	&	2.0	&	0.14\\
Jasper 2	&	9.0		&	5.0		&	5.0 & & & 0.23\\
Ork		&	6.0		&	5.0		&	4.0	& & & 0.18\\
Roberto	&	19.0	&	8.0		&	13.0 & & & 0.47\\
Xiaong	&	17.0	&	14.0	&	10.0 & & & 0.49\\
\hline
Gosia	&	16.0	&	9.0		&	6.0 & & & 0.37\\
Hamdi	&	14.0	&	12.0	&	15.0 & & & 0.49\\
Michael	&	6.0		&	8.0		&	13.0 & & & 0.32\\
Sil		&	14.0	&	17.0	&	13.0 & & & 0.52\\
Victoria	&	9.0	&	6.0		&	5.0 & & & 0.24\\
Chu		&	8.0		&	6.0		&	2.0 & & & 0.19\\
\hline
Koen	&	11.0	&	9.0		&	11.0 & & & 0.38\\
Bas		&	15.0	&	12.0	&	9.0 & & & 0.44\\
Stratos	&	12.0	&	3.0		&	5.0 & & & 0.24\\

\hline
\end{tabular}






\section{Implementation}

\begin{figure}[ht]
\begin{center}
\label{fig:sonicgesture}
\includegraphics[width=0.6\linewidth]{figures/sonicgesture.jpg}
\end{center}
\caption{screenshot of Sonic Gesture}
\end{figure}

Sonic Gesture has been implemented in C++. Almost all computer vision algorithms used in Sonic Gesture are part of OpenCV, an open source library made for this kind of software. For the graphical interface QT is used. Sonic Gesture has been release as Open Source software and is released under the Apache license. The software can be downloaded, modified and distributed freely from the website\footnote{http://code.google.com/p/sonic-gesture}.

The program can capture directly from a webcam or it can read movies with recorded material. It has 2 modes, one 'finder' mode where hand poses in the video stream are detected. The second mode is the 'capture' mode, which is used to label movies. When labeling a movie in this mode a text file is created with frame positions of the labels. This can later be used to extract the correct frame and extract training data for the classifier. This mode has been used a lot during the gathering of the dataset.

\section{Time performance}
A lot of effort has been put into getting Sonic Gesture as fast as possible. Initially Sonic Gesture was written in Python and used the Python API of OpenCV. Soon it became clear that Python was to limited to do high performance graphic processing so a switch to C++ was made. 

The performance of Sonic Gesture depends on how fast the testing systems CPU power is, if the OpenCV IPP extention is used but also how fast the camera can capture frames. On a Macbook Pro, 2.4 GHz intel core 2 duo with 4 GB of memory using the build-in iSight as camera, processing one frame takes 65 ms on average. This is with the full dataset of 2072 datapoints with 3780 dimensions using the KNN classifier. KNN works fine with low numbers of datapoint, but with high numbers it starts to slow down. Still it is quite fast; around 25 ms on average. SVM will probably perform much faster with a high number of datapoints but we couldn't get the SVM implementation of OpenCV to work. An other expensive operation is the face detection algoritm, when tweaked it takes around 13 ms to locale a face in a image. Since a face position isn't required constantly this is done only every 10th frame, so valuable computation time is saved. An other surprisingly expensive operation is the resizing of a image. Resizing an image to a small size is a crucial part of the pipe line, because some operations on a big image will take too much time. But resizing a image using interpolation is a expensive operation. Where interpolation is not required, for example for rendering on the screen, it is disabled saving more computing time. 

37.9\% KNN
8.4\% color space convertion
7.6\% image resizing
2.3\% haar classifier (19% if not every 10th frame).

\section{Discussion}
As you can see there is a big difference in performance



